{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "mount_file_id": "1Chjwo-gsNgQRAIabQDMKzisg5rs1RIAh",
      "authorship_tag": "ABX9TyP9xbDAwNDdBzdzmX/9SDW2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pko89403/ScalaAndSpark/blob/master/RapidsAI_XGBoost_On_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd219riiwrS1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e33c95e6-038e-4719-b14d-819ed87482e6"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul 10 13:38:35 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t7ICaWkwx6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cb6900c1-83dc-41bf-d03f-27737cd3c78c"
      },
      "source": [
        "# !wget https://repo1.maven.org/maven2/ai/rapids/cudf/0.9.2/cudf-0.9.2-cuda10-1.jar\n",
        "!wget https://repo1.maven.org/maven2/ai/rapids/cudf/0.9.1/cudf-0.9.1-cuda10-1.jar"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-10 13:38:37--  https://repo1.maven.org/maven2/ai/rapids/cudf/0.9.2/cudf-0.9.2-cuda10-1.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 151.101.52.209\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|151.101.52.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 64759406 (62M) [application/java-archive]\n",
            "Saving to: ‘cudf-0.9.2-cuda10-1.jar’\n",
            "\n",
            "cudf-0.9.2-cuda10-1 100%[===================>]  61.76M   161MB/s    in 0.4s    \n",
            "\n",
            "2020-07-10 13:38:40 (161 MB/s) - ‘cudf-0.9.2-cuda10-1.jar’ saved [64759406/64759406]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBYyx8Wtw7tO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7459ea9b-0e52-44b2-8a44-4e26c5cef77a"
      },
      "source": [
        "!wget https://repo1.maven.org/maven2/ai/rapids/xgboost4j_2.x/1.0.0-Beta5/xgboost4j_2.x-1.0.0-Beta5.jar"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-10 13:38:41--  https://repo1.maven.org/maven2/ai/rapids/xgboost4j_2.x/1.0.0-Beta5/xgboost4j_2.x-1.0.0-Beta5.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 151.101.52.209\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|151.101.52.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 349225621 (333M) [application/java-archive]\n",
            "Saving to: ‘xgboost4j_2.x-1.0.0-Beta5.jar’\n",
            "\n",
            "xgboost4j_2.x-1.0.0 100%[===================>] 333.05M   244MB/s    in 1.4s    \n",
            "\n",
            "2020-07-10 13:38:48 (244 MB/s) - ‘xgboost4j_2.x-1.0.0-Beta5.jar’ saved [349225621/349225621]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf0OHZOoxGl-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "90ed5c82-1457-4e79-bc75-99f2e0d52790"
      },
      "source": [
        "!wget https://repo1.maven.org/maven2/ai/rapids/xgboost4j-spark_2.x/1.0.0-Beta5/xgboost4j-spark_2.x-1.0.0-Beta5.jar"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-10 13:38:50--  https://repo1.maven.org/maven2/ai/rapids/xgboost4j-spark_2.x/1.0.0-Beta5/xgboost4j-spark_2.x-1.0.0-Beta5.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 151.101.52.209\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|151.101.52.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4829218 (4.6M) [application/java-archive]\n",
            "Saving to: ‘xgboost4j-spark_2.x-1.0.0-Beta5.jar’\n",
            "\n",
            "xgboost4j-spark_2.x 100%[===================>]   4.61M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-07-10 13:38:50 (33.5 MB/s) - ‘xgboost4j-spark_2.x-1.0.0-Beta5.jar’ saved [4829218/4829218]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viAMMgkQxID7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "09950614-e382-4238-c988-14b421804119"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra\n",
            "  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n",
            "  fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 33 not upgraded.\n",
            "Need to get 35.8 MB of archives.\n",
            "After this operation, 140 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u252-b09-1~18.04 [27.5 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u252-b09-1~18.04 [8,250 kB]\n",
            "Fetched 35.8 MB in 3s (11.3 MB/s)\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "(Reading database ... 144379 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u252-b09-1~18.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u252-b09-1~18.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PusVwM-ExPTh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a87437fe-ba23-4989-bfba-94bac87022d6"
      },
      "source": [
        "!wget http://mirror.navercorp.com/apache/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-10 13:39:07--  http://mirror.navercorp.com/apache/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
            "Resolving mirror.navercorp.com (mirror.navercorp.com)... 125.209.216.167\n",
            "Connecting to mirror.navercorp.com (mirror.navercorp.com)|125.209.216.167|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 232530699 (222M) [application/octet-stream]\n",
            "Saving to: ‘spark-2.4.5-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-2.4.5-bin-had 100%[===================>] 221.76M  2.13MB/s    in 23s     \n",
            "\n",
            "2020-07-10 13:39:30 (9.84 MB/s) - ‘spark-2.4.5-bin-hadoop2.7.tgz’ saved [232530699/232530699]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cUsppwexilU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f82ac8a9-6071-43e2-a741-ec5c6d0531ed"
      },
      "source": [
        "!apt-get install tar"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tar is already the newest version (1.29b-2ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 33 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYqLCptHxyHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xf spark-2.4.5-bin-hadoop2.7.tgz"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEpdwUOMx3C7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f96c3f2d-ce73-4d74-80cc-903e7fa3cf3c"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cudf-0.9.2-cuda10-1.jar    spark-2.4.5-bin-hadoop2.7.tgz\n",
            "drive\t\t\t   xgboost4j_2.x-1.0.0-Beta5.jar\n",
            "sample_data\t\t   xgboost4j-spark_2.x-1.0.0-Beta5.jar\n",
            "spark-2.4.5-bin-hadoop2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k50rms5Hx6dN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "37af32f4-606a-48e3-a7a4-2ae644506698"
      },
      "source": [
        "!pip install pyspark==2.4.5 findspark"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark==2.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)\n",
            "\u001b[K     |████████████████████████████████| 217.8MB 64kB/s \n",
            "\u001b[?25hCollecting findspark\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/2d/2e39f9a023479ea798eed4351cd66f163ce61e00c717e03c37109f00c0f2/findspark-1.4.2-py2.py3-none-any.whl\n",
            "Collecting py4j==0.10.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-2.4.5-py2.py3-none-any.whl size=218257927 sha256=92af766539e0e59e7c84f448029cd8980a27a527356fc7be330450f38b6180ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark, findspark\n",
            "Successfully installed findspark-1.4.2 py4j-0.10.7 pyspark-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxr5GLozzgEq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "c468794a-61a0-4719-b912-f460128e81e4"
      },
      "source": [
        "!wget https://github.com/rapidsai/spark-examples/raw/master/datasets/mortgage-small.tar.gz\n",
        "!tar xvf mortgage-small.tar.gz"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-10 13:40:20--  https://github.com/rapidsai/spark-examples/raw/master/datasets/mortgage-small.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rapidsai/spark-examples/master/datasets/mortgage-small.tar.gz [following]\n",
            "--2020-07-10 13:40:20--  https://raw.githubusercontent.com/rapidsai/spark-examples/master/datasets/mortgage-small.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 103288 (101K) [application/octet-stream]\n",
            "Saving to: ‘mortgage-small.tar.gz’\n",
            "\n",
            "mortgage-small.tar. 100%[===================>] 100.87K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-07-10 13:40:20 (4.27 MB/s) - ‘mortgage-small.tar.gz’ saved [103288/103288]\n",
            "\n",
            "mortgage-small/\n",
            "mortgage-small/train/\n",
            "mortgage-small/train/mortgage-small.csv\n",
            "mortgage-small/trainWithEval/\n",
            "mortgage-small/trainWithEval/test.csv\n",
            "mortgage-small/eval/\n",
            "mortgage-small/eval/mortgage-small.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUjBtXYAyzT9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00655150-36a2-4c70-e802-e2b04c0fcf43"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDvYltpeyDZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ['SPARK_HOME']=\"/content/spark-2.4.5-bin-hadoop2.7\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PzjlUQhy8qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    spark.stop\n",
        "except:\n",
        "    pass"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGRp6NoDy_vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "import pyspark\n",
        "from pyspark.sql.session import SparkSession\n",
        "\n",
        "findspark.init()\n",
        "\n",
        "\n",
        "spark = (SparkSession\n",
        "    .builder\n",
        "    .appName(\"myspark\")\n",
        "    .config('spark.jars', '/content/cudf-0.9.2-cuda10-1.jar,/content/xgboost4j_2.x-1.0.0-Beta5.jar,/content/xgboost4j-spark_2.x-1.0.0-Beta5.jar')         \n",
        "    .getOrCreate())\n",
        "\n",
        "spark.sparkContext.addPyFile(\"/content/xgboost4j-spark_2.x-1.0.0-Beta5.jar\")\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRp0o6GxzA3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "593e794f-187a-41e8-f075-da365935ed81"
      },
      "source": [
        "print(spark.version)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoqKGfCJzGyS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ml.dmlc.xgboost4j.scala.spark import XGBoostClassificationModel, XGBoostClassifier\n",
        "from ml.dmlc.xgboost4j.scala.spark.rapids import GpuDataReader, CrossValidator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "from pyspark.sql.types import FloatType, IntegerType, StructField, StructType\n",
        "from time import time"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqKsXFXbzL6l",
        "colab_type": "text"
      },
      "source": [
        "### Data reader uses GpuDataReader(spark) \n",
        "instead of spark.read 2. setFeaturesCol function on CPU is replaced by setFeaturesCols(features) a. \n",
        "> This also eliminates the need for vectorization (assembling multiple feature columns in to one column) since we can read multiple columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LOIhQTVzm20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label = 'delinquency_12'\n",
        "schema = StructType([\n",
        "    StructField('orig_channel', FloatType()),\n",
        "    StructField('first_home_buyer', FloatType()),\n",
        "    StructField('loan_purpose', FloatType()),\n",
        "    StructField('property_type', FloatType()),\n",
        "    StructField('occupancy_status', FloatType()),\n",
        "    StructField('property_state', FloatType()),\n",
        "    StructField('product_type', FloatType()),\n",
        "    StructField('relocation_mortgage_indicator', FloatType()),\n",
        "    StructField('seller_name', FloatType()),\n",
        "    StructField('mod_flag', FloatType()),\n",
        "    StructField('orig_interest_rate', FloatType()),\n",
        "    StructField('orig_upb', IntegerType()),\n",
        "    StructField('orig_loan_term', IntegerType()),\n",
        "    StructField('orig_ltv', FloatType()),\n",
        "    StructField('orig_cltv', FloatType()),\n",
        "    StructField('num_borrowers', FloatType()),\n",
        "    StructField('dti', FloatType()),\n",
        "    StructField('borrower_credit_score', FloatType()),\n",
        "    StructField('num_units', IntegerType()),\n",
        "    StructField('zip', IntegerType()),\n",
        "    StructField('mortgage_insurance_percent', FloatType()),\n",
        "    StructField('current_loan_delinquency_status', IntegerType()),\n",
        "    StructField('current_actual_upb', FloatType()),\n",
        "    StructField('interest_rate', FloatType()),\n",
        "    StructField('loan_age', FloatType()),\n",
        "    StructField('msa', FloatType()),\n",
        "    StructField('non_interest_bearing_upb', FloatType()),\n",
        "    StructField(label, IntegerType()),\n",
        "])\n",
        "features = [ x.name for x in schema if x.name != label ]\n",
        "\n",
        "train_data = GpuDataReader(spark).schema(schema).option('header', True).csv('/content/mortgage-small/train')\n",
        "eval_data = GpuDataReader(spark).schema(schema).option('header', True).csv('/content/mortgage-small/eval')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1utF0lok5U-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "0f58408d-0bbe-44da-fd8b-96a8ce505996"
      },
      "source": [
        "\n",
        "\"\"\" For CPU\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "def vectorize(data_frame):\n",
        "    to_floats = [ col(x.name).cast(FloatType()) for x in data_frame.schema ]\n",
        "    return (VectorAssembler()\n",
        "        .setInputCols(features)\n",
        "        .setOutputCol('features')\n",
        "        .transform(data_frame.select(to_floats))\n",
        "        .select(col('features'), col(label)))\n",
        "\n",
        "# CPU version : CPU 버전은 Vectorization이 필요하다.  모든 컬럼들을 feature 컬럼 하나로 뭉쳐야한다\n",
        "train_data = spark.read.schema(schema).option('header', True).csv('/home/mortgage-small/train')\n",
        "eval_data = spark.read.schema(schema).option('header', True).csv('/home/mortgage-small/eval')\n",
        "\n",
        "train_data = vectorize(train_data)\n",
        "eval_data = vectorize(eval_data)\n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "\" For CPU\\nfrom pyspark.ml.feature import VectorAssembler\\nfrom pyspark.sql.functions import col\\n\\ndef vectorize(data_frame):\\n    to_floats = [ col(x.name).cast(FloatType()) for x in data_frame.schema ]\\n    return (VectorAssembler()\\n        .setInputCols(features)\\n        .setOutputCol('features')\\n        .transform(data_frame.select(to_floats))\\n        .select(col('features'), col(label)))\\n\\n# CPU version : CPU 버전은 Vectorization이 필요하다.  모든 컬럼들을 feature 컬럼 하나로 뭉쳐야한다\\ntrain_data = spark.read.schema(schema).option('header', True).csv('/home/mortgage-small/train')\\neval_data = spark.read.schema(schema).option('header', True).csv('/home/mortgage-small/eval')\\n\\ntrain_data = vectorize(train_data)\\neval_data = vectorize(eval_data)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y7QL7fn5iBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = { \n",
        "    'eta': 0.1,\n",
        "    'gamma': 0.1,\n",
        "    'missing': 0.0,\n",
        "    'treeMethod': 'gpu_hist',\n",
        "    'maxDepth': 10, \n",
        "    'maxLeaves': 256,\n",
        "    'growPolicy': 'depthwise',\n",
        "    'objective': 'binary:logistic',\n",
        "    'minChildWeight': 30.0,\n",
        "    'lambda_': 1.0,\n",
        "    'scalePosWeight': 2.0,\n",
        "    'subsample': 1.0,\n",
        "    'nthread': 1,\n",
        "    'numRound': 100,\n",
        "    'numWorkers': 1,\n",
        "}\n",
        "classifier = XGBoostClassifier(**params).setLabelCol(label).setFeaturesCols(features)\n",
        "# Then build the evaluator and the hyperparameters\n",
        "evaluator = (MulticlassClassificationEvaluator()\n",
        "    .setLabelCol(label))\n",
        "param_grid = (ParamGridBuilder()\n",
        "    .addGrid(classifier.maxDepth, [3, 6])\n",
        "    .addGrid(classifier.numRound, [10, 20])\n",
        "    .build())\n",
        "# Finally the corss validator\n",
        "cross_validator = (CrossValidator()\n",
        "    .setEstimator(classifier)\n",
        "    .setEvaluator(evaluator)\n",
        "    .setEstimatorParamMaps(param_grid)\n",
        "    .setNumFolds(3))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsJtrMFg5uUM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ce1af4c4-0f6e-4aa5-dd23-9f7c0ef2b07a"
      },
      "source": [
        "def with_benchmark(phrase, action):\n",
        "    start = time()\n",
        "    result = action()\n",
        "    end = time()\n",
        "    print('{} takes {} seconds'.format(phrase, round(end - start, 2)))\n",
        "    return result\n",
        "model = with_benchmark('Cross-Validation', lambda: cross_validator.fit(train_data))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation takes 27.48 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXOc_ReVzOMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = { \n",
        "    'eta': 0.1,\n",
        "    'gamma': 0.1,\n",
        "    'missing': 0.0,\n",
        "    'treeMethod': 'gpu_hist',\n",
        "    'maxDepth': 10, \n",
        "    'maxLeaves': 256,\n",
        "    'growPolicy': 'depthwise',\n",
        "    'objective': 'binary:logistic',\n",
        "    'minChildWeight': 30.0,\n",
        "    'lambda_': 1.0,\n",
        "    'scalePosWeight': 2.0,\n",
        "    'subsample': 1.0,\n",
        "    'nthread': 1,\n",
        "    'numRound': 100,\n",
        "    'numWorkers': 1\n",
        "}\n",
        "# numberWorkers = Shuld be set to number of GPU Core or CPU Core  \n",
        "# For GPU\n",
        "classifier = XGBoostClassifier(**params).setLabelCol(label).setFeaturesCols(features)\n",
        "# For CPU\n",
        "#classifier = XGBoostClassifier(**params).setLabelCol(label).setFeaturesCol('features')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQlNUcK50wCd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9fa4fffe-fc5d-4d56-e032-92bebcc2318d"
      },
      "source": [
        "def with_benchmark(phrase, action):\n",
        "    start = time()\n",
        "    result = action()\n",
        "    end = time()\n",
        "    print('{} takes {} seconds'.format(phrase, round(end - start, 2)))\n",
        "    return result\n",
        "model = with_benchmark('Training', lambda: classifier.fit(train_data))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training takes 1.04 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-7842gd9jB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "03be7141-8e06-4fb1-f6c7-6edb190483ed"
      },
      "source": [
        "def transform():\n",
        "    result = model.transform(eval_data).cache()\n",
        "    result.foreachPartition(lambda _: None)\n",
        "    return result\n",
        "result = with_benchmark('Transforming', transform)\n",
        "result.select(label, 'rawPrediction', 'probability', 'prediction').show(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transforming takes 1.49 seconds\n",
            "+--------------+--------------------+--------------------+----------+\n",
            "|delinquency_12|       rawPrediction|         probability|prediction|\n",
            "+--------------+--------------------+--------------------+----------+\n",
            "|           0.0|[5.90152835845947...|[0.99727220018394...|       0.0|\n",
            "|           0.0|[5.90152835845947...|[0.99727220018394...|       0.0|\n",
            "|           0.0|[5.90152835845947...|[0.99727220018394...|       0.0|\n",
            "|           0.0|[5.34092235565185...|[0.99523139884695...|       0.0|\n",
            "|           0.0|[5.34092235565185...|[0.99523139884695...|       0.0|\n",
            "+--------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E49e3RD9qIb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bb844f98-7e0d-4080-cd39-b01b863372a4"
      },
      "source": [
        "accuracy = with_benchmark(\n",
        "    'Evaluation',\n",
        "    lambda: MulticlassClassificationEvaluator().setLabelCol(label).evaluate(result))\n",
        "print('Accuracy is ' + str(accuracy))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation takes 0.19 seconds\n",
            "Accuracy is 0.995580557003928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMTFS4ta97os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spark.stop()"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}